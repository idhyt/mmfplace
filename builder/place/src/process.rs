use anyhow::Result;
use chrono::Datelike;
use once_cell::sync::OnceCell;
use std::borrow::Cow;
use std::path::PathBuf;
use std::sync::atomic::{AtomicUsize, Ordering};
use std::sync::Arc;
use tokio::sync::mpsc;
use tokio::sync::Semaphore;
use tracing::{debug, debug_span, error, info, warn};
use tracing_futures::Instrument;
use walkdir::WalkDir;

use super::db::{get_connection, insert_finfo, query_finfo, update_finfo, FileInfo};
use super::target::{Target, OUTPUT_GEN};

use config::CONFIG;
use tools::metadata_extractor;

fn error_with_exit() -> ! {
    std::process::exit(1);
}

// ä¸´æ—¶å…±äº«æ•°æ®ï¼Œæˆ‘ä¸çŸ¥é“è¯¥å–ä»€ä¹ˆåå­—hhh...
#[derive(Debug, Clone, Default)]
struct TempData {
    input: PathBuf,
    output: PathBuf,
    test: bool,
    rename: bool,
    total: usize,
}

static TEMPDATA: OnceCell<TempData> = OnceCell::new();

fn temp_init(input: PathBuf, output: PathBuf, test: bool, rename: bool, total: usize) {
    TEMPDATA
        .set(TempData {
            input,
            output,
            test,
            rename,
            total,
        })
        .expect("TempData is already initialized")
}
fn temp_get() -> &'static TempData {
    TEMPDATA.get().expect("TempData is not initialized")
}

pub async fn do_process(
    input: PathBuf,
    output: PathBuf,
    test: bool,
    rename_with_ymd: bool,
) -> Result<()> {
    // let (input, output, test) = (&temp_get().input, &temp_get().output, temp_get().test);
    let total = walkdir::WalkDir::new(&input)
        .into_iter()
        .filter_map(Result::ok)
        .filter(|e| e.file_type().is_file())
        .count();
    temp_init(input, output, test, rename_with_ymd, total);
    let (input, output, test) = (&temp_get().input, &temp_get().output, temp_get().test);
    info!(input=?input, total=total, output=?output, test=test, "start process");

    // MPSC mode
    let concurrency: usize = CONFIG.batch_size;
    let channel_size: usize = 100;
    let (tx, mut rx) = mpsc::channel::<Target>(channel_size);
    let processed_count = Arc::new(AtomicUsize::new(0));
    let semaphore = Arc::new(Semaphore::new(concurrency));

    let root_span = debug_span!("process");
    let _enter = root_span.enter();

    let consumer = tokio::spawn({
        let processed_count = Arc::clone(&processed_count);
        let root_span = root_span.clone();
        async move {
            while let Some(fdt) = rx.recv().await {
                let span = debug_span!("task_place", file = ?fdt.path);
                async {
                    if let Err(e) = do_place(fdt, &processed_count).await {
                        error!(error=%e, "place error");
                        error_with_exit();
                    }
                }
                .instrument(span)
                .await;
            }
            info!("finished consumer");
        }
        .instrument(root_span)
    });

    let producer = tokio::spawn({
        // let input = temp_get().input.clone();
        let tx = tx; // tx.clone();
        let semaphore = Arc::clone(&semaphore);
        let root_span = root_span.clone();

        async move {
            let mut tasks = Vec::new();
            for entry in WalkDir::new(input)
                .into_iter()
                .filter_map(Result::ok)
                .filter(|e| e.file_type().is_file())
            {
                let path = entry.path().to_path_buf();
                let tx = tx.clone();
                let semaphore = Arc::clone(&semaphore);
                let root_span = root_span.clone();

                let task = tokio::spawn(
                    async move {
                        let span = debug_span!("task_parse", file = ?path);
                        async {
                            let _permit = semaphore.acquire().await.unwrap();
                            match do_parse(path).await {
                                Ok(t) => {
                                    if let Err(e) = tx.send(t).await {
                                        error!("send task error: {:#?}", e);
                                        error_with_exit();
                                    }
                                }
                                Err(e) => {
                                    error!(error=%e, "parse error");
                                    error_with_exit();
                                }
                            }
                            // drop(_permit);
                        }
                        .instrument(span)
                        .await
                    }
                    .instrument(root_span),
                );

                tasks.push(task);

                if tasks.len() >= channel_size {
                    let _ = futures::future::join_all(tasks).await;
                    tasks = Vec::new();
                }
            }
            futures::future::join_all(tasks).await;
            // drop(tx);
            info!("finished producer");
        }
    });

    // producer.await?;
    // consumer.await?;
    let _ = tokio::join!(producer, consumer);

    info!("all done");
    Ok(())
}

// è®¡ç®—æ–‡ä»¶hash -> åˆ¤æ–­hashæ˜¯å¦åœ¨æ•°æ®åº“ä¸­ -> å­˜åœ¨ -> è·å–partséƒ¨åˆ†æ‹¼æ¥è·¯å¾„æ˜¯å¦å­˜åœ¨ -> å­˜åœ¨è·³è¿‡/ä¸å­˜åœ¨æ‹·è´
//                                      -> ä¸å­˜åœ¨ -> è§£ææ‰€æœ‰æ—¶é—´(å…ƒæ•°æ®+æ–‡ä»¶å±æ€§) -> å–æœ€æ—© -> æ’å…¥æ•°æ®åº“ -> æ‹·è´æ–‡ä»¶
async fn do_parse(path: PathBuf) -> Result<Target> {
    debug!(file=?path, "ğŸš€ begin parse file");
    let mut target = Target::new(path)?;

    // if test mode, don't check exists
    if temp_get().test {
        debug!(file=?target.path, "ğŸ’¡ test mode, skip exists check");
    } else {
        let conn = get_connection().lock().unwrap();
        if let Some(history) = query_finfo(&conn, &target.hash)? {
            target.dealt = true;
            target.parts = Some(history.parts.into());
            // æ›´æ–° earliestï¼Œåè¾¹éœ€è¦è®¾ç½®æ–‡ä»¶å±æ€§æ—¶é—´
            target.set_earliest(Some(history.earliest as u64))?;
        }
    }

    // å¦‚æœæŸ¥åˆ°ï¼Œè¯´æ˜ä¹‹å‰å·²å¤„ç†è¿‡äº†ï¼Œåˆ™ä¸å†è¿›è¡Œå…ƒæ•°æ®è§£æ
    if target.dealt {
        debug!(file = ?target.path, "file is already dealt before");
        return Ok(target);
    }

    // æ˜¯å¦éœ€è¦è·å–æ–‡ä»¶ç±»å‹
    let captype = CONFIG
        .typeregex
        .ignore
        .as_ref()
        .map_or(true, |ignore| !ignore.contains(&target.extension));
    // å¦‚æœéœ€è¦å¿½ç•¥ï¼Œåˆ™è®¾ç½®typeå­—æ®µï¼Œåè¾¹é€»è¾‘å°†è·³è¿‡è·å–æ–‡ä»¶ç±»å‹
    if !captype {
        debug!(file = ?target.path, "ğŸ’¡ the file type is ignored");
        target.ftype = Some(target.extension.clone());
    }

    // è·å–æ–‡ä»¶å…ƒæ•°æ®å¹¶è§£æå‡ºæ‰€æœ‰æ—¶é—´æ ¼å¼
    let texts = metadata_extractor(&target.path).await?;
    'outer: for text in texts.iter() {
        // è¿‡æ»¤å­—ç¬¦ä¸²
        if let Some(ignore) = &CONFIG.dateregex.ignore {
            for black in ignore {
                if text.contains(black) {
                    debug!(black = black, text = text, "skip black string");
                    continue 'outer;
                }
            }
        }

        // è·å–æ–‡ä»¶type
        if target.ftype.is_none() {
            for capture in &CONFIG.typeregex.list {
                if let Ok(t) = capture.capture(text) {
                    info!(
                        text = text,
                        ftype = t,
                        "ğŸ‰ success parse filetype from text"
                    );
                    target.ftype = Some(t);
                    break;
                }
            }
        }

        // è·å–æ–‡ä»¶æ—¶é—´
        if let Ok(dt) = dateparser::parse(text) {
            if dt.year() < 1975 {
                warn!(file=?target.path, datetime=%dt, "ğŸ’¡ skip the datetime < 1975");
            } else {
                info!(text = text, datetime = %dt, "ğŸ‰ success parse datetime from text");
                target.tinfo.parsedtimes.push(dt);
            }
        }
    }
    target.set_earliest(None)?;

    Ok(target)
}

async fn do_place(mut target: Target, processed_count: &Arc<AtomicUsize>) -> Result<()> {
    let count = processed_count.fetch_add(1, Ordering::SeqCst) + 1;
    let total = temp_get().total;
    debug!(file=?target.path, "ğŸš€ begin place {} file", count);
    target.set_output(&temp_get().output, temp_get().rename)?;

    if temp_get().test {
        info!(from=?target.path, to=?target.output, "âœ… [{count}/{total}] success test finish");
        return Ok(());
    }

    // åœ¨è§£æé˜¶æ®µï¼Œå¦‚æœåœ¨æ•°æ®åº“ä¸­æ‰¾æ‰“åŒ hashï¼Œè¯´æ˜ä¹‹å‰å¤„ç†è¿‡äº†ï¼Œä¼šæ ‡è®°å­—æ®µ dealt=trueï¼Œå¹¶ä½¿ç”¨å¤„ç†è¿‡çš„ parts ä½œä¸ºè·¯å¾„
    // å½“å­—æ®µ dealt=false æ—¶ï¼Œè¯´æ˜å½“å‰èµ°äº†è§£ææµç¨‹
    // ä½†æ˜¯åœ¨å¹¶å‘è¿‡ç¨‹ä¸­ï¼Œä¼šå­˜åœ¨ç›¸åŒ hash çš„ /path/to/A å’Œ /path/to/B åŒæ—¶è¢«å¤„ç†

    // æ²¡æœ‰èµ° parse æµç¨‹ï¼Œä½¿ç”¨çš„å†å² parts, æ•°æ®åº“ä¸éœ€è¦å¤„ç†ï¼Œç›´æ¥æ‹·è´å³å¯
    if target.dealt {
        target.copy_with_times()?;
        info!(from=?target.path, to=?target.output, "âœ… [{count}/{total}] success place with history parsed finish");
        return Ok(());
    }

    // å¤„ç†å¹¶å‘ä¸­å¯èƒ½å­˜åœ¨åŒ hash
    {
        let parts = target.parts.as_ref().unwrap();
        let finfo = FileInfo {
            parts: Cow::Borrowed(parts),
            hash: Cow::Borrowed(&target.hash),
            earliest: target.get_earliest()?.timestamp(),
        };
        let conn = get_connection().lock().unwrap();
        // å…ˆæŸ¥æ˜¯å¦å­˜åœ¨
        let find = query_finfo(&conn, &target.hash)?;
        if find.is_none() {
            // ä¸å­˜åœ¨ç›´æ¥æ’å…¥æ•°æ®åº“å³å¯
            insert_finfo(&conn, &finfo).map_err(|e| {
                anyhow::anyhow!(
                    "insert hash error file={:?}, hash={} error={:?}",
                    target.path,
                    target.hash,
                    e
                )
            })?;
            target.copy_with_times()?;
            info!(from=?target.path, to=?target.output, "âœ… [{count}/{total}] success place with new parsed finish");
            return Ok(());
        }

        let history = find.unwrap();
        info!(current=?parts, history=?history.parts, "same hash file found, compare the time and overwrite it");
        let history_file = OUTPUT_GEN(&temp_get().output, &history.parts.to_vec());
        // å¦‚æœå·²ç»å­˜åœ¨äº†ï¼Œæ¯”å¯¹ eraiest timeï¼Œå¦‚æœå½“å‰çš„æ›´æ—©ï¼Œåˆ™æ›´æ–°ï¼Œå¦åˆ™ç›´æ¥ä¸¢å¼ƒ
        if finfo.earliest < history.earliest {
            // åˆ é™¤åŸæ¥çš„æ–‡ä»¶
            if history_file.is_file() {
                std::fs::remove_file(&history_file)?;
            }
            // æ›´æ–°æ•°æ®åº“
            update_finfo(&conn, &finfo)?;
            target.copy_with_times()?;
            info!(from=?target.path, to=?target.output, "âœ… [{count}/{total}] success place (<history) update finish");
        }
        // æ—¶é—´æ™šï¼Œåˆ™ä¸¢å¼ƒ
        else {
            // æ£€æŸ¥ä¸‹åŸå§‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨ï¼Œåˆ™éœ€è¦å¤åˆ¶è¿‡å»
            // æ›´æ–° output
            target.output = history_file;
            if !target.output.is_file() {
                warn!(file=?target.output, "âš ï¸ history file not exists, restore it");
                // è®¾ç½® earliest
                target.set_earliest(Some(history.earliest as u64))?;
                // å¤åˆ¶
                target.copy_with_times()?;
            }
            info!(from=?target.path, to=?target.output, "âœ… [{count}/{total}] success place (>=history) finish");
        }
    }
    Ok(())
}

#[cfg(test)]
mod tests {
    use super::*;
    use chrono::prelude::*;
    use chrono::Utc;

    fn get_root() -> PathBuf {
        PathBuf::from(std::env::var("CARGO_MANIFEST_DIR").unwrap())
            .parent()
            .unwrap()
            .parent()
            .unwrap()
            .to_path_buf()
    }

    #[tokio::test]
    async fn test_do_parse() {
        let tests = get_root().join("tests");
        let input = tests.join("2002/11/simple.png");
        let output = get_root().join("tests");
        temp_init(input.clone(), output.clone(), true, false, 1);
        let mut target = do_parse(input.clone()).await.unwrap();
        println!("target: {:#?}", target);
        assert_eq!("simple", target.name);
        assert_eq!("png", target.extension);
        assert_eq!(Some("jpg".to_string()), target.ftype);
        assert_eq!(target.tinfo.parsedtimes.len(), 3);
        assert_eq!(target.hash, "a18932e314dbb4c81c6fd0e282d81d16");
        assert_eq!(
            target.get_earliest().unwrap(),
            Utc.with_ymd_and_hms(2002, 11, 16, 0, 0, 0).unwrap()
        );
        assert!(target.tinfo.attrtimes.len() >= 2);

        target.set_output(&output, false).unwrap();
        let copy_path = target.output.clone();
        println!("copy_path: {:?}", copy_path);
        assert_eq!(copy_path, output.join("2002/11/simple_01.jpg"));
        assert_eq!(target.parts.unwrap(), vec!["2002", "11", "simple_01.jpg"]);

        // now we copy to a new file
        let dup_file = input.with_file_name("simple_01.jpg");
        std::fs::copy(&input, &dup_file).unwrap();
        let input = tests.join("2002/11/simple.jpg");
        let mut target = do_parse(input.clone()).await.unwrap();
        println!("new target: {:#?}", target);
        assert_eq!(target.hash, "a18932e314dbb4c81c6fd0e282d81d16");
        assert_eq!("simple", target.name);
        assert_eq!("jpg", target.extension);
        assert_eq!(Some("jpg".to_string()), target.ftype);
        assert_eq!(
            target.get_earliest().unwrap(),
            Utc.with_ymd_and_hms(2002, 11, 16, 0, 0, 0).unwrap()
        );

        target.set_output(&output, false).unwrap();
        let copy_path = target.output.clone();
        println!("copy_path: {:?}", copy_path);
        assert_eq!(copy_path, output.join("2002/11/simple_02.jpg"));
        assert_eq!(
            *target.parts.as_ref().unwrap(),
            vec!["2002", "11", "simple_02.jpg"]
        );

        target.set_output(&output, true).unwrap();
        let copy_path = target.output.clone();
        assert_eq!(copy_path, output.join("2002/11/2002-11-16.jpg"));

        std::fs::remove_file(&dup_file).unwrap();
    }
}
